1. What percentage of papers in the ICSE proceedings contain empirical evaluations?
2. How has the quantity of empirical evaluations in ICSE papers changed over time?
3. Are hypotheses clearly stated in the examined empirical studies?
4. How many replicated studies are there in the ICSE sample?
5. What are the types of studies performed in ICSE proceedings?
6. How often are negative results reported in empirical studies?
7. What role does the discussion section play in ICSE papers?
8. How is the soundness of empirical evaluations assessed in ICSE papers?
9. What criteria are used to define a sound empirical evaluation?
10. How many empirical studies use legal methods of analysis?
11. What is the distribution of sampling types in empirical studies from ICSE proceedings?
12. How many empirical studies use random sampling?
13. How many empirical studies use convenience sampling?
14. How many empirical studies use purposeful sampling?
15. What populations do empirical studies in the ICSE proceedings sample from?
16. How many studies in the ICSE sample use industry-based data?
17. What are the evaluation methods used in empirical studies published in ICSE?
18. How many empirical studies use examples as a form of validation?
19. How many empirical studies provide detailed case studies?
20. What do prominent researchers recommend for improving empirical evaluations?
21. What are the most common threats to validity in ICSE empirical studies?
22. How often are vested interests made explicit in the ICSE papers?
23. What is the importance of replication in empirical software engineering research?
24. How does the peer-review process affect the soundness of empirical studies?
25. How many papers in the ICSE sample are categorized as exploratory case studies?
26. What is the predominant source of data for subjects in ICSE empirical studies?
27. How is hypothesis formulation regarded in literature recommendations for empirical studies?
28. Are self-confirmatory studies prevalent in ICSE proceedings?
29. What are the weaknesses of the empirical evaluations noted in ICSE papers?
30. What are the highlights of empirical evaluation practices in ICSE papers?
31. How is the quality of empirical evaluations in ICSE assessed over different time periods?
32. How does the definition of study type affect the replication of empirical studies?
33. What biases are introduced by investigator sampling in empirical studies?
34. How often do empirical studies in ICSE proceedings involve student data?
35. What are the common mistakes found in the empirical analysis of ICSE papers?
36. What role do workshops and panels play in improving empirical evaluations?
37. How is the quantity of empirical evaluations in journals compared to ICSE proceedings?
38. How are the terms "empirical evaluation" and "empirical discussion" defined and used?
39. How many studies in ICSE proceedings evaluate new tools and models?
40. How are hypotheses justified in empirical studies according to ICSE proceedings?
41. What are the differences between self-evaluations and independent evaluations in ICSE papers?
42. What does the literature say about the trend of increasing empirical studies in software engineering?
43. How do ICSE papers address external validity concerns?
44. What are the primary goals of empirical studies in ICSE proceedings?
45. How do the ICSE proceedings define and categorize empirical study types?
46. How is the process of selecting study subjects described in empirical ICSE papers?
47. How are the goals of empirical studies detailed in ICSE proceedings?
48. What is the relationship between industrial collaboration and empirical studies in ICSE?
49. How are statistical methods used in evaluating empirical studies within ICSE papers?
50. What makes an empirical study scientifically fraught according to ICSE papers?
51. How strongly is statistical confidence emphasized in empirical ICSE studies?
52. How do ICSE papers address replication under differing conditions?
53. How is the balance between theoretical and empirical work managed in ICSE studies?
54. How often are empirical studies isolated without replication in ICSE proceedings?
55. How do ICSE empirical studies incorporate or reference existing theory?
56. What improvements are suggested for increasing the rigour of ICSE empirical studies?
57. How are varying levels of evaluation ambiguity addressed in ICSE proceedings?
58. What processes are suggested for independent validation and analysis of empirical studies in ICSE?
59. How does the soundness of empirical evaluations influence the acceptance of ICSE papers?
60. How significant are the trends in empirical evaluation findings over time in ICSE papers?
61. How are internal validity concerns mitigated in empirical evaluations according to ICSE proceedings?
62. What is the significance of detailed experimental designs in mitigating threats to validity?
63. How does the ICSE community view the importance of developing a body of empirical knowledge?
64. How are empirical studies categorized based on the type of research question they address?
65. What differences exist between author perspective and investigator perspective in study definitions?
66. How do ICSE papers define and interpret replicate study findings?
67. How are the primary research questions in empirical studies framed in ICSE proceedings?
68. What is the role of meta-analysis in synthesizing empirical studies in ICSE proceedings?
69. What types of comparisons are drawn between different software engineering tools in ICSE papers?
70. How often do ICSE empirical studies follow the GQM (Goal Question Metric) approach?
71. What proportion of ICSE empirical studies fail to clearly define their methodology?
72. How do ICSE papers address the balance between academic and practical empirical research?
73. What specific areas of empirical evaluation are identified for improvement in ICSE proceedings?
74. What common themes are observed in the recommendations for improving empirical software engineering studies?
75. How frequently do ICSE empirical studies report on the benefits and drawbacks of their findings?
76. How are the concepts of internal replication and validity evaluated in ICSE proceedings?
77. What are the statistical methods used to assess trends in empirical evaluation counts in ICSE papers?