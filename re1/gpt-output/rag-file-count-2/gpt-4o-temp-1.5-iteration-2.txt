1. What is the trend in the quantity of empirical evaluations in Requirements Engineering (RE) over the years?
2. Has the soundness of empirical evaluations in RE improved over the years?
3. What are the key factors that contribute to empirical evaluation soundness in RE?
4. How frequently are hypotheses defined in RE empirical studies?
5. Are replicated studies common in RE empirical research?
6. What proportion of RE studies report primarily negative results?
7. How are empirical evaluation methods categorized in RE?
8. What are the common threats to validity in RE empirical studies?
9. How do authors typically select the population and sample for RE empirical studies?
10. What is the use of industry-based data in RE empirical research?
11. How is the term "empirical validation" commonly used in RE studies?
12. What types of sampling are most frequently utilized in RE empirical studies?
13. How do RE researchers employ examples in their empirical evaluations?
14. Are there distinct trends in study types over the evolution of RE empirical research?
15. How consistent are RE researchers in defining the type of their empirical studies?
16. What are the common design components in RE empirical studies?
17. How is the legal analysis of scales of measurement addressed in RE empirical studies?
18. How have the evaluation types evolved in the field of RE?
19. To what extent do RE studies disclose potential biases?
20. How is the population type identified in RE empirical studies?
21. What is the frequency of quasi-experiments in RE empirical research?
22. How often are empirical evaluations self-confirmatory in RE?
23. Do RE empirical studies adequately communicate their methodology for replication purposes?
24. Do RE empirical studies exhibit a notable trend in reporting negative results?
25. What is the distribution of empirical study types across different time periods in RE?
26. How do RE empirical studies define and operationalize their hypotheses?
27. How are threats to internal validity addressed in RE empirical research?
28. What are the common contexts in which RE empirical studies are conducted?
29. What methodologies are used to analyze data in RE empirical studies?
30. How do RE empirical studies address external validity?
31. What role do discussions play in empirical evaluations of RE?
32. How do RE empirical studies justify their use of particular evaluation types?
33. What are the implications of the absence of replicated studies in RE?
34. How do RE researchers link data analysis to study hypotheses?
35. What are the predominant types of empirical studies in RE?
36. How do RE empirical studies report their experimental design?
37. What proportion of RE empirical studies employ industrial data versus student data?
38. Are vested interests and potential biases typically disclosed in RE empirical studies?
39. How is the GQM (Goal Question Metric) approach applied in RE evaluations?
40. What are the challenges in defining the study type in RE empirical research?
41. How do RE empirical studies categorize their methodological approaches?
42. How often do RE empirical studies specify alternative hypotheses?
43. How do RE empirical studies deal with the legal analysis of data?
44. What are the strategies for ensuring construct validity in RE research?
45. How do RE empirical studies balance between qualitative and quantitative methods?
46. What are the major trends in the use of evaluation components in RE?
47. How is experience reported and utilized in RE empirical studies?
48. How do RE empirical studies define their research context and objectives?
49. How do authors in RE empirical studies handle sampling bias?
50. What are the common findings generalized to different populations in RE research?
51. How has the use of software engineering industry data in RE studies evolved?
52. What is the role of peer-review in the quality of RE empirical research?
53. How are empirical critique and empirical discussion differentiated in RE research?
54. How do RE empirical studies contribute to building a body of knowledge?
55. Are self-evaluated studies prevalent in RE research?
56. What are the key recommendations from prominent researchers regarding RE empirical evaluation?
57. How are evaluation criteria defined and applied in RE empirical studies?
58. What is the role of case studies in RE empirical research?
59. How do RE studies address replication logic in their methodology?
60. What are the implications of the lack of hypothesis specification in RE empirical studies?
61. How has empirical research methodology evolved in RE over different decades?
62. To what extent are qualitative methods employed in RE empirical studies?
63. How do RE empirical studies achieve statistical significance in their findings?
64. How do RE empirical studies report threats to construct validity?
65. What are the implications of the findings regarding RE studies' external validity?
66. How are exploratory case studies utilized in RE empirical research?
67. What are the main sources of data for RE empirical evaluations?
68. How do RE researchers present and interpret their findings?
69. Are discussions and examples considered adequate forms of validation in RE empirical studies?
70. How do RE empirical studies handle the explicitness of their evaluation methods?
71. What is the impact of the learning curve on the soundness of RE empirical studies?
72. How do RE empirical studies contribute to the practical application of findings?
73. How consistent are RE empirical studies in reporting their research methodology?
74. What recommendations are there for future RE empirical research based on past studies?
75. How do RE empirical studies address the need for independent evaluations?
76. How is the citation and reference to previous work handled in RE empirical studies?
77. What role do workshops and panels play in shaping the methodologies of RE empirical evaluations?