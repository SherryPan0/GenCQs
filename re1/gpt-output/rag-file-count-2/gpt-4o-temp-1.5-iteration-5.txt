1. What trends have been observed in the number of empirical evaluations in ICSE proceedings over the years?
2. How has the soundness of empirical evaluations in ICSE papers evolved over time?
3. What are the key parameters that define a sound empirical evaluation in software engineering research?
4. What are the most common types of empirical studies published in ICSE proceedings?
5. What are the main challenges faced in conducting empirical evaluations in software engineering?
6. How frequently are hypotheses explicitly stated in empirical software engineering studies at ICSE?
7. What is the role of replication in the body of knowledge for software engineering research?
8. How often are industry participants included in empirical software engineering studies?
9. What is the balance between using industrial and student data in empirical studies?
10. How are the findings of empirical studies in software engineering generalized to different populations?
11. What are the common threats to validity in empirical software engineering research?
12. How are vested interests reported and minimized in empirical studies?
13. What percentage of empirical studies in ICSE proceedings are self-evaluations?
14. What guidelines exist for conducting high-quality empirical research in software engineering?
15. How are research questions and hypotheses formulated in empirical software engineering studies?
16. What are the common types of sampling used in empirical software engineering research?
17. How is the target population for empirical studies defined in software engineering research?
18. What types of evaluation methods are used in empirical software engineering studies?
19. How is data analysis performed in empirical software engineering research?
20. What are the key findings from empirical evaluations of ICSE papers?
21. How does the use of examples as validation in empirical studies impact the research?
22. What is the importance of clarifying the type of study in empirical software engineering research?
23. What are the criteria for interpreting the findings of empirical studies in software engineering?
24. How is the object of study and purpose defined in empirical software engineering research?
25. What are the main types of empirical methods used in software engineering research?
26. What are the common types of experimental design used in empirical software engineering research?
27. How are logical links between data and replication logic established in empirical studies?
28. How is the context of the study defined in empirical software engineering research?
29. How are empirical studies of software engineering critiqued for lack of rigor?
30. What recommendations exist for improving empirical evaluations in software engineering?
31. How has the quantity of empirical evaluations performed in ICSE proceedings changed over time?
32. What role does statistical analysis play in evaluating empirical software engineering research?
33. How are internal replications conducted to ensure consistency in empirical software engineering studies?
34. What are the major improvements needed in the soundness of empirical evaluations in ICSE papers?
35. What are the highlights of empirical evaluations in ICSE proceedings?
36. How are qualitative results used to evaluate empirical studies in software engineering?
37. How are empirical evaluations of software engineering studies validated?
38. What are the key metrics for measuring the success of empirical evaluations in software engineering?
39. How does the absence of replicated studies affect the body of knowledge in software engineering?
40. What are the implications of the lack of improvement in self-confirmatory studies in ICSE?
41. What is the impact of researcher bias on the outcomes of empirical software engineering studies?
42. How is the balance between exploratory and quasi-controlled studies in ICSE proceedings?
43. What are the major concerns for empirical software engineering research highlighted over the years?
44. How is the term "empirical validation" used in software engineering studies?
45. What are the differences between various clusters of ICSE papers in terms of empirical evaluations?
46. How do empirical software engineering studies address issues of external validity?
47. What are the different levels of evaluation in empirical software engineering studies?
48. What are the recommendations for addressing the challenges of empirical evaluations in software engineering?
49. How are empirical studies of software engineering documented in ICSE proceedings?
50. What are the specific areas for improvement in empirical evaluations in ICSE proceedings?
51. What are the implications of the lack of negative results in empirical software engineering research?
52. How is the success rate of empirical evaluations measured in ICSE proceedings?
53. What are the common findings from empirical studies of object-oriented artifacts, methods, and processes?
54. What role do keynote talks, panels, and workshops play in supporting empirical evaluations in software engineering?
55. How is the importance of replicated studies emphasized in empirical software engineering research?
56. What is the significance of having well-defined hypotheses in empirical software engineering studies?
57. How are threats to validity categorized and addressed in empirical software engineering research?
58. What is the state of replication and theory revision in empirical software engineering research?
59. How often are studies published in ICSE proceedings later replicated in other journals and conferences?
60. What are the common pitfalls in performing data analysis for empirical evaluations in software engineering?
61. How do empirical software engineering studies contribute to building a body of knowledge?
62. What types of evidence are produced by empirical software engineers?
63. What are the differences in the quantity and quality of empirical evaluations in early versus recent ICSE proceedings?
64. How do software engineering researchers define and justify the soundness of their empirical studies?
65. What are the trends in the use of industrial data for empirical studies in ICSE proceedings?
66. How do empirical software engineering studies handle the use of different types of measurement scales?
67. What are the lessons learned from prominent participants in software engineering empirical evaluation?
68. How are empirical evaluations used to inform the improvement of software engineering practices?
69. What are the common themes in the critiques of empirical software engineering studies?
70. How do the results from empirical studies influence the direction of software engineering research?
71. What are the recommendations for improving the quantity and quality of empirical evaluations in ICSE proceedings?
72. How are empirical evaluations of software engineering papers reviewed and accepted in ICSE proceedings?
73. What are the different clusters of empirical evaluations in ICSE and their characteristics?
74. How are empirical software engineering studies replicated under similar and differing conditions?
75. What is the role of meta-analysis in empirical software engineering research?
76. How are biases reported and controlled in empirical evaluations of software engineering?
77. What are the future directions for empirical evaluations in software engineering research?