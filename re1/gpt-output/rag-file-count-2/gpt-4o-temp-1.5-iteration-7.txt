1. What is the volume of empirical work performed over the lifetime of ICSE?
2. How has the soundness of empirical work performed changed over the lifetime of ICSE?
3. What is the definition of "sound" empirical evaluation in Requirements Engineering?
4. How are empirical evaluations categorized, and what are the parameters used in this categorization?
5. What are the trends in the number of empirical evaluations over the years in ICSE proceedings?
6. Which types of empirical methods are most commonly used in Requirements Engineering research?
7. How frequently are hypotheses clearly stated in empirical studies?
8. What is the significance of replication in empirical studies according to the literature?
9. How often are studies in Requirements Engineering replicated?
10. What are the common threats to the validity of empirical studies in this field?
11. To what extent are self-confirmatory studies prevalent in empirical research in Requirements Engineering?
12. How are target and sample populations defined and used in empirical evaluations?
13. What are the typical outcomes of empirical evaluations in Requirements Engineering papers?
14. How do empirical evaluation practices in ICSE compare to those in other software engineering journals and conferences?
15. What are the main critiques of empirical evaluations in Requirements Engineering?
16. What does the literature suggest about the importance of explicit research questions and hypotheses?
17. What improvements are suggested for conducting empirical evaluations in Requirements Engineering?
18. How is the process for selecting subjects and objects in studies typically described?
19. What are the criteria for legal analysis in empirical research?
20. How are industrial and student data used in empirical evaluations?
21. What vested interests should be made explicit to minimize bias in empirical evaluations?
22. What role do examples play in empirical validation in Requirements Engineering?
23. How should discussions be distinguished from empirical evaluations in research papers?
24. How has the focus on empirical evaluations evolved in keynote talks, panels, and workshops?
25. What are the primary methods of data analysis used in empirical studies?
26. What guidelines exist for writing good research papers in Requirements Engineering?
27. What steps are needed for the improvement of empirical research practices in Requirements Engineering?
28. What are the common factors that lead to the success of empirical studies?
29. How are study terms such as "study type", "sampling type", "target population", and "evaluation type" defined and used?
30. How does the research community view the contribution of empirical studies to the body of knowledge in software engineering?
31. What are the statistical measures used to evaluate the hypotheses in empirical research?
32. What is the significance of the level of significance in empirical studies?
33. How are the results of descriptive and statistical analyses presented in empirical research papers?
34. What are the observed weaknesses in empirical evaluations in ICSE proceedings?
35. What are the key components of experimental design as described in the literature?
36. How do case studies and quasi-studies contribute to empirical evaluations?
37. How should biases be reported in self-evaluated work?
38. What are the recommendations for empirical study design as per prominent researchers?
39. What role do threats to validity play in empirical research?
40. How can the sampling methods in empirical evaluations be improved?
41. What are the documented trends in the types of studies published in ICSE over the years?
42. How do the perspectives of authors and investigators differ regarding study types?
43. What are the main challenges in defining study types in empirical evaluations?
44. What measures are taken to ensure the internal validity of empirical evaluations?
45. How is the increase in empirical evaluations indicative of the maturing field of Requirements Engineering?
46. What are the statistical probabilities of Type I errors in empirical evaluations?
47. What is the process used to draw statistical inferences in empirical research?
48. How are qualitative conclusions derived from empirical evaluations?
49. How is external replication planned for studies beyond ICSE?
50. What are the implications of the lack of hypothesis specification in empirical evaluations?
51. How does the peer-review process influence the quality of empirical evaluations in ICSE?
52. What are the documented impacts of self-confirmation bias on empirical research?
53. How are examples incorrectly used as validations in empirical studies?
54. What are the recommended practices for using levels of measurement in data analysis?
55. How often do papers present a mismatch between the type of study and the type of empirical evaluation described?
56. What trends are observed in the frequency of experience reports in ICSE papers?
57. How have discussion sections evolved in their role relative to empirical evaluations?
58. Who are the leading researchers in empirical evaluation in Requirements Engineering, and what benchmarks have they set?
59. What are the observed improvements in empirical evaluations due to increased community awareness?
60. How is the construct validity of new empirical parameters justified?
61. What role does internal replication play in ensuring the consistency of empirical evaluations?
62. How are the generalizability and sample size of empirical studies ensured?
63. What changes in empirical evaluation are prompted by reduced numbers of N/A (not applicable) papers in recent years?
64. How has the role of industrial data in empirical evaluations evolved over the years?
65. What are the implications of the increased proportion of papers with evaluation components in recent ICSE proceedings?
66. To what extent do researchers rely on implicit references to theory in their empirical studies?
67. What are the main recommendations from key publications on empirical studies in Requirements Engineering?
68. How has the debate on hypotheses formulation impacted empirical research practices?
69. What are the common explanations for the severe absence of hypothesis formulation in empirical studies?
70. How do empirical studies measure the appropriateness of hypotheses?
71. What are the highlight points observed from empirical evaluations in recent ICSE papers?
72. What are some of the systemic problems identified in empirical empirical research practice in Requirements Engineering?
73. What are the key suggestions for addressing the weaknesses in empirical evaluations in Requirements Engineering?
74. What are the current trends in the use of meta-analysis in empirical research practice?
75. How have empirical research trends evolved in the context of the overall progress in software engineering?
76. What proposals exist for improving the frequency and quality of empirical evaluations?
77. How are empirical research results interpreted to influence future research directions in Requirements Engineering?